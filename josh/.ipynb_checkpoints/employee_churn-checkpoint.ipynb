{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6671fb82-1962-44c1-aa4f-4e44883b3832",
   "metadata": {},
   "source": [
    "# Can you help reduce employee turnover?\n",
    "\n",
    "## üìñ Background\n",
    "You work for the human capital department of a large corporation. The Board is worried about the relatively high turnover, and your team must look into ways to reduce the number of employees leaving the company.\n",
    "\n",
    "The team needs to understand better the situation, which employees are more likely to leave, and why. Once it is clear what variables impact employee churn, you can present your findings along with your ideas on how to attack the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5929b9-9d9a-457a-99ab-be05f27176f9",
   "metadata": {},
   "source": [
    "## üíæ The data\n",
    "The department has assembled data on almost 10,000 employees. The team used information from exit interviews, performance reviews, and employee records.\n",
    "\n",
    "- \"department\" - the department the employee belongs to.\n",
    "- \"promoted\" - 1 if the employee was promoted in the previous 24 months, 0 otherwise.\n",
    "- \"review\" - the composite score the employee received in their last evaluation.\n",
    "- \"projects\" - how many projects the employee is involved in.\n",
    "- \"salary\" - for confidentiality reasons, salary comes in three tiers: low, medium, high.\n",
    "- \"tenure\" - how many years the employee has been at the company.\n",
    "- \"satisfaction\" - a measure of employee satisfaction from surveys.\n",
    "- \"avg_hrs_month\" - the average hours the employee worked in a month.\n",
    "- \"left\" - \"yes\" if the employee ended up leaving, \"no\" otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee76ec-6cc0-4cc7-b6ed-eba4feb6ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/employee_churn_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfd8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ecc34-7949-4090-9129-684c491c05cb",
   "metadata": {},
   "source": [
    "## üí™ Competition challenge\n",
    "\n",
    "Create a report that covers the following:\n",
    "1. Which department has the highest employee turnover? Which one has the lowest?\n",
    "2. Investigate which variables seem to be better predictors of employee departure.\n",
    "3. What recommendations would you make regarding ways to reduce employee turnover?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b2aa2a-1f53-4343-93bf-9a09c503fbf5",
   "metadata": {},
   "source": [
    "## üßë‚Äç‚öñÔ∏è Judging criteria\n",
    "\n",
    "| CATEGORY | WEIGHTING | DETAILS                                                              |\n",
    "|:---------|:----------|:---------------------------------------------------------------------|\n",
    "| **Recommendations** | 35%       | <ul><li>Clarity of recommendations - how clear and well presented the recommendation is.</li><li>Quality of recommendations - are appropriate analytical techniques used & are the conclusions valid?</li><li>Number of relevant insights found for the target audience.</li></ul>       |\n",
    "| **Storytelling**  | 35%       | <ul><li>How well the data and insights are connected to the recommendation.</li><li>How the narrative and whole report connects together.</li><li>Balancing making the report in-depth enough but also concise.</li></ul> |\n",
    "| **Visualizations** | 20% | <ul><li>Appropriateness of visualization used.</li><li>Clarity of insight from visualization.</li></ul> |\n",
    "| **Votes** | 10% | <ul><li>Up voting - most upvoted entries get the most points.</li></ul> |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e920d2e-bddd-4396-9644-a6568d323bbf",
   "metadata": {},
   "source": [
    "## ‚úÖ Checklist before publishing into the competition\n",
    "- Rename your workspace to make it descriptive of your work. N.B. you should leave the notebook name as notebook.ipynb.\n",
    "- Remove redundant cells like the judging criteria, so the workbook is focused on your story.\n",
    "- Make sure the workbook reads well and explains how you found your insights.\n",
    "- Check that all the cells run without error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53a49ea-ddf4-4a19-941a-5ce52b679e77",
   "metadata": {},
   "source": [
    "## ‚åõÔ∏è Time is ticking. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400b2d3c-0a18-4089-a84c-f898dfb2d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368a4a0-a2ef-42ea-97ff-cba8c6b73ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df.hist()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cde798-18c3-4ce7-bf0e-be5746665ed9",
   "metadata": {},
   "source": [
    "Missing columns: `'deparment'`, `'salary'`, `'left'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350726c8-03fe-493e-8ea8-109701b6396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "departments = sorted(set(df.department), key=lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d7d6ce-f9b3-4f1a-9747-5a3e3376558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac75fd0-8208-4ba3-b4e4-6798f407abea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dep in enumerate(departments):\n",
    "    df.department = df.department.replace(dep, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6a6b37-e333-4b04-8782-4d768751fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.salary = df.salary.replace('low', 0)\n",
    "df.salary = df.salary.replace('medium', 1)\n",
    "df.salary = df.salary.replace('high', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198fb2a6-59ee-410b-a052-0d28b162f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.left = df.left.replace('no', 0)\n",
    "df.left = df.left.replace('yes', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c17b871-41f6-4314-8af2-633a4a0f9065",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Which department has the highest employee turnover? Which one has the lowest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce74be-46d7-4968-9936-2b56a6883e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left = df[df.left == 1]\n",
    "df_stay = df[df.left == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecef186a-b463-40a0-a44b-544223d5f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_counts = {\n",
    "    dep: df_left[df_left.department == i].shape[0]\n",
    "    for i, dep in enumerate(departments)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e5c0e-e80b-4eda-978c-4854b0d7e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in sorted(leave_counts.items(), key=lambda x: x[1]):\n",
    "    print('{:<20}: {}'.format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33375655-0d35-4109-a297-dcc9fb6b69ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The department with the most turnover is: '{}' ({})\".format(*max(leave_counts.items(), key=lambda x: x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c291ed-d99d-4841-99f8-b1ff26ecf22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The department with the least turnover is: '{} ({})'\".format(*min(leave_counts.items(), key=lambda x: x[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df023334-6720-44a6-a0ac-5e350f2d6abf",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "Investigate which variables seem to be better predictors of employee departure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a0b5da-b213-4724-a185-28f2d8ed6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9934b68-d1e8-4658-aaed-819556f83058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f1cb00-38fe-4de8-ba6d-5cc8e6eabab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = df_left.hist(figsize=(12, 9), alpha=0.3, density=True)\n",
    "\n",
    "df_stay.hist(figsize=(12, 9), ax=list(itertools.chain.from_iterable(axes))[:10], alpha=0.3, density=True)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca4b26-2ca5-4346-b329-fe1f46888b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = df_left.hist(figsize=(12, 9), alpha=0.3)\n",
    "\n",
    "df_stay.hist(figsize=(12, 9), ax=list(itertools.chain.from_iterable(axes))[:10], alpha=0.3)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba18e3ca-f8f7-4bc9-b6c3-55dc4d1ac1a6",
   "metadata": {},
   "source": [
    "Brainstorming:\n",
    "\n",
    "* \"Maybe they work too hard, then want to leave, but they get reviewed well because they worked so hard\"\n",
    "    * So is there a positive correlation between `'avg_hrs_month'` and `'review'`? No... actually, they're negatively correlated.\n",
    "* Spring-board theory -- they're reviewed too well, they leave\n",
    "* Start with a model using only `'review'`, `'tenure'`, `'avg_hrs_month'`, and `'satisfaction'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dd8ee1-9211-495d-8fe5-8b4b3c6a2fd7",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97c144c-84e3-4781-9180-741528d1da6e",
   "metadata": {},
   "source": [
    "General description of technique:\n",
    "    \n",
    "* Assumes that all variables are independent of each other\n",
    "* Uses Bayes' Theorem to make an updated prediction of the probability of a result given each of the variables\n",
    "    * Recall Bayes' Theorem:\n",
    "        * $P(\\text{A}|\\text{B}) = \\frac{P(\\text{B}|\\text{A}) * P(\\text{A})}{P(\\text{B})}$\n",
    "        * $ \\text{posterior} = \\frac{\\text{likelihood} * \\text{prior}}{\\text{evidence}} $\n",
    "    * For example:\n",
    "        * $P(\\text{left}|\\text{promoted}) = \\frac{P(\\text{promoted}|\\text{left})*P(\\text{left})}{P(\\text{promoted})}$\n",
    "* Note that `likelihood` and `prior` should all be computed using _only_ the training set.\n",
    "* Also note, `evidence` is a constant for a given observation, so it can be ignored. It is essentially the normalization of the distribution.\n",
    "* For multiple $x$ (because of the assumption of independence), the total probability can be written as $$ P(y | x_1, ..., x_n) = P(y) \\prod_{i=1}^n P(x_i|y)$$\n",
    "* We can of course use the log-probability instead $$ \\log{P(y | x_1, ..., x_n)} = \\log{P(y)} + \\sum_{i=1}^n \\log{P(x_i|y)} $$\n",
    "* This requires the assumption of a given likelihood for each possible output condition.\n",
    "    * For example, for \"Gaussian Naive Bayes\":\n",
    "        * $ P(x_i|y) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp{-\\frac{1}{2}\\big(\\frac{x - \\mu}{\\sigma}\\big)^2}$\n",
    "* The likelihoods for the categorical features must be handled differently: $$ P(x_i = t | y=c; \\alpha ) = \\frac{N_{xc} + \\alpha}{N_c + \\alpha n_i} $$\n",
    "    * $N_xc$ is the number of times feature $x$ appears in the data with category $c$\n",
    "    * $N_c$ is the number of counts of category $c$\n",
    "    * $\\alpha$ is a smoothing parameter\n",
    "    * $n_i$ is the number of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e7431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, percent_train):\n",
    "    num_data = len(data)\n",
    "    \n",
    "    all_indices = np.random.choice(num_data, num_data)\n",
    "    \n",
    "    split_index = int(np.floor(num_data*percent_train))\n",
    "    train_indices, test_indices = np.split(all_indices, [split_index])\n",
    "    \n",
    "    return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393739b8",
   "metadata": {},
   "source": [
    "## Manual version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df47592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal(x, mu, sigma):\n",
    "    return -(((x-mu)/sigma)**2)/2 - np.log(sigma) - np.log(2*np.pi)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d5f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, percent_train=0.9)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e28f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_left = df_train[df_train.left == 1]\n",
    "train_stay = df_train[df_train.left == 0]\n",
    "\n",
    "train_left.shape, train_stay.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201a245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_left = df_test[df_test.left == 1]\n",
    "test_stay = df_test[df_test.left == 0]\n",
    "\n",
    "test_left.shape, test_stay.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = train_left.mean()\n",
    "stdvs = train_left.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed6f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_left_given_data = np.log(train_left.shape[0]/df.shape[0])\n",
    "\n",
    "for c in ['review', 'tenure', 'avg_hrs_month', 'satisfaction']:\n",
    "    p_left_given_data += log_normal(df_test[c], means[c], stdvs[c])\n",
    "    \n",
    "p_left_given_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871173e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stay_given_data = np.log(train_stay.shape[0]/df.shape[0])\n",
    "\n",
    "for c in ['review', 'tenure', 'avg_hrs_month', 'satisfaction']:\n",
    "    p_stay_given_data += log_normal(df_test[c], means[c], stdvs[c])\n",
    "    \n",
    "p_stay_given_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdbc0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_left_indices = np.where(p_left_given_data > p_stay_given_data)\n",
    "\n",
    "predictions = np.zeros(len(df_test))\n",
    "predictions[predict_left_indices] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff3f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = np.sum(np.abs(predictions - df_test['left']))\n",
    "percent_incorrect = incorrect / len(df_test)\n",
    "percent_incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b29e5",
   "metadata": {},
   "source": [
    "## sklearn version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab8eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd7b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(\n",
    "    df_train.drop(\n",
    "        columns=[\n",
    "            'left', 'department', 'promoted', 'projects', 'salary', 'bonus'\n",
    "        ]\n",
    "    ),\n",
    "    df_train['left']\n",
    ")\n",
    "\n",
    "predictions = gnb.predict(\n",
    "    df_test.drop(\n",
    "        columns=[\n",
    "            'left', 'department', 'promoted', 'projects', 'salary', 'bonus'\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "incorrect = np.sum(np.abs(predictions - df_test['left']))\n",
    "percent_incorrect = incorrect / len(df_test)\n",
    "percent_incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89431dff",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "* How could we improve NB?\n",
    "    * Use KDE for the likelihoods\n",
    "    * Linear Discriminant Analysis (LDA) or Quadratic Discriminant Analysis (QDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88dc42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
